{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e03f400d",
   "metadata": {},
   "source": [
    "# NN with backpropagation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d2d94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 1]]\n",
      "[[0.77795804 0.9332739  0.85785536 0.91266578 0.85754394 0.68047707\n",
      "  0.80409013 0.71913631]\n",
      " [0.77752388 0.92154919 0.83707103 0.89538976 0.85128554 0.6639689\n",
      "  0.78450607 0.69518796]\n",
      " [0.77194598 0.92826646 0.85420174 0.90739997 0.85131723 0.67686419\n",
      "  0.7947783  0.71345235]\n",
      " [0.78118165 0.9245895  0.8337584  0.90366505 0.85532544 0.68085693\n",
      "  0.78891424 0.70582937]\n",
      " [0.78092912 0.92486814 0.83995936 0.89871283 0.85494243 0.66538212\n",
      "  0.79039891 0.69842299]\n",
      " [0.77257349 0.92143406 0.83973377 0.89923105 0.84836503 0.67293418\n",
      "  0.78325008 0.70222266]\n",
      " [0.77694793 0.92457498 0.84078819 0.90242834 0.85258139 0.6752445\n",
      "  0.78887502 0.70516499]\n",
      " [0.77122603 0.91977754 0.83898523 0.89648469 0.8466765  0.66913055\n",
      "  0.78058738 0.69889458]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = [[1,0,0,0,0,0,0,0],[0,1,0,0,0,0,0,0],[0,0,1,0,0,0,0,0],[0,0,0,1,0,0,0,0],\n",
    "[0,0,0,0,1,0,0,0],[0,0,0,0,0,1,0,0],[0,0,0,0,0,0,1,0],[0,0,0,0,0,0,0,1]]\n",
    "X = np.array(x)\n",
    "Y = X\n",
    "print(Y)\n",
    "\n",
    "# We need to have 8 inputs (each number in a row of the matrix),a hidden layer with 3 nodes + bias and an output layer with 8 nodes\n",
    "\n",
    "n_input = 8 # We need to have 8 inputs (each number in a row of the matrix)\n",
    "n_hidden = 3\n",
    "n_output = 8\n",
    "# Weights\n",
    "np.random.seed(42)\n",
    "W1 = np.random.rand(n_input, n_hidden) # 8 x 3 Weights for input to hidden\n",
    "#print(W1)\n",
    "W2 = np.random.rand(n_hidden, n_output) # 3 x 8 Weights for hidden to output\n",
    "#print(W2)\n",
    "# Biases\n",
    "b1 = np.random.rand(n_hidden) # Bias for hidden layer (3)\n",
    "b2 = np.random.rand(n_output) # Bias for output layer (3)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def first_layer(X):\n",
    "    return sigmoid(np.dot(X, W1) + b1)\n",
    "\n",
    "def second_layer(hidden_output):\n",
    "    return sigmoid(np.dot(hidden_output, W2) + b2)\n",
    "\n",
    "second_layer_output_0 = second_layer(first_layer(X))\n",
    "print(second_layer_output_0)\n",
    "# def sigmoid_derivative(x):\n",
    "#     return x * (1 - x)\n",
    "\n",
    "def loss(Y, second_layer_output):\n",
    "    return np.mean((Y - second_layer_output) ** 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bell_inequality)",
   "language": "python",
   "name": "bell_inequality"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
